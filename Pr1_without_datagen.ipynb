{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21ceed5f",
   "metadata": {},
   "source": [
    "# Sequential neural network for prediction of continuous values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf51c27",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5bf200bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b12e19",
   "metadata": {},
   "source": [
    "Helpful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "89367a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that retrieves the input variable columns from the CSV and returns a pandas dataframe containing the columns\n",
    "def retrieve_X_df(df, verbose=True):\n",
    "  \"\"\"\n",
    "  :param df: Required, the dataframe containing the input and output variables. The first 900 values for each observation are assumed the input variables.\n",
    "  :param verbose: Optional, default==True, prints the shape of the dataframe after retrieving the input columns.\n",
    "\n",
    "  :return: dataframe containing the input data. \n",
    "  \"\"\"\n",
    "  df = df.iloc[:,0:900]\n",
    "  if verbose:\n",
    "    print(\"df shape: \", df.shape)\n",
    "  return df\n",
    "\n",
    "#function that retrieves the target columns from the CSV and returns a pandas dataframe containing the columns\n",
    "def retrieve_y_df(df, n_last_cols = 3, verbose=True):\n",
    "  \"\"\"\n",
    "  :param df: Required, the dataframe containing the input and target variables. \n",
    "  :param n_last_cols: Optional, default==3, The number of column values for each observation that are the target variables.\n",
    "  :param verbose: Optional, default==True, prints the shape of the dataframe after retrieving the target columns.\n",
    "\n",
    "  :return: dataframe containing the target data. \n",
    "  \"\"\"\n",
    "  df = df.iloc[:,-n_last_cols:]\n",
    "  df.columns = ['amplitude','X','Y']\n",
    "  if verbose:\n",
    "    print(\"df shape: \", df.shape)\n",
    "  return df\n",
    "\n",
    "#function that converts the input dataframe into 2-D matrix\n",
    "def turn_rows_into_np_matrix(df, width=30, height=30,verbose=True):\n",
    "  \"\"\"\n",
    "  :param df: Required, the dataframe containing the input variables. \n",
    "  :param width: Optional, default==30, The width to use when transforming a 1-D representation of data to 2-D representation.\n",
    "  :param height: Optional, default==30, The height to use when transforming a 1-D representation of data to 2-D representation.\n",
    "  :param verbose: Optional, default==True, opperate in verbose mode.\n",
    "\n",
    "  :return: numpy ndarray shape(n_observations, width, height)\n",
    "  \"\"\"\n",
    "  # save the dataframe as a numpy arrray\n",
    "  np_img_matrices = df.to_numpy()\n",
    "  if (verbose):\n",
    "    print(\"len numpy array: \", len(np_img_matrices))\n",
    "\n",
    "  # for each row, turn into a width x height matrix using the shape method\n",
    "  # set the shape\n",
    "  shape = (len(np_img_matrices),width,height)\n",
    "  # re shape the array\n",
    "  np_img_matrices = np_img_matrices.reshape(shape)\n",
    "\n",
    "  if verbose:\n",
    "    # print the first \"image\" matrix\n",
    "    print(np_img_matrices[0])\n",
    "\n",
    "  return np_img_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7bd115",
   "metadata": {},
   "source": [
    "Read csv-files and retrieve the train and test datasets. Split train dataset into train and validation datasets with ratio 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6d6cf3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape:  (9000, 900)\n",
      "df shape:  (9000, 3)\n",
      "df shape:  (1000, 900)\n",
      "df shape:  (1000, 3)\n",
      "df shape:  (2000, 900)\n",
      "df shape:  (2000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   4.2439,  702.5571, -118.9555],\n",
       "       [   2.7615,  -67.0084,  747.8185],\n",
       "       [   3.162 , -831.5248,  691.4152],\n",
       "       ...,\n",
       "       [   3.9983,  724.0626,  239.1365],\n",
       "       [   1.9245,  233.1289, -277.3137],\n",
       "       [   1.8139, -425.4246, -232.5975]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = \"https://userweb.jlab.org/~tbritton/Hackathon2021_DataSets/Problem1/\"\n",
    "\n",
    "#Read the train csv-file\n",
    "df_train = pd.read_csv(os.path.join(source,\"train.csv\"), na_values=['NA', '?'], header=None)\n",
    "\n",
    "#Set up a splitting ratio\n",
    "train_pct = 0.9\n",
    "train_cut = int(len(df_train) * train_pct)\n",
    "\n",
    "#Retrieve the train X and train y datasets\n",
    "df_tr = df_train[0:train_cut]\n",
    "df_train_X = retrieve_X_df(df_tr)\n",
    "df_train_y = retrieve_y_df(df_tr).to_numpy()\n",
    "\n",
    "#Retrieve the validation X and train y datasets\n",
    "df_val = df_train[train_cut:]\n",
    "df_val_X = retrieve_X_df(df_val)\n",
    "df_val_y = retrieve_y_df(df_val).to_numpy()\n",
    "\n",
    "#Read the test csv-file\n",
    "df_test = pd.read_csv(os.path.join(source,\"test.csv\"), na_values=['NA', '?'], header=None)\n",
    "\n",
    "#Retrieve the test X and test y datasets\n",
    "df_test_X = retrieve_X_df(df_test)\n",
    "df_test_y = retrieve_y_df(df_test).to_numpy()\n",
    "\n",
    "df_train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11265d71",
   "metadata": {},
   "source": [
    "Turn the rows into matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5724613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 30, 30)\n",
      "(1000, 30, 30)\n"
     ]
    }
   ],
   "source": [
    "train_X = turn_rows_into_np_matrix(df_train_X, 30,30, False)\n",
    "print(train_X.shape)\n",
    "val_X = turn_rows_into_np_matrix(df_val_X, 30,30, False)\n",
    "print(val_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d93983",
   "metadata": {},
   "source": [
    "Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f1086f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential neural network with selected parameters\n",
    "def create_sequential_dnn(width, num_nodes = (16, 16, 16), activations = ('relu','relu','relu'), outputs = 3):\n",
    "\n",
    "  model = Sequential()\n",
    "\n",
    "  if len(num_nodes) != len(activations):\n",
    "    print('The length of the number of nodes array and activations array must be the same.')\n",
    "    sys.exit()\n",
    "\n",
    "  # loop over the number of nodes\n",
    "  for (i, n) in enumerate(num_nodes):\n",
    "    if i == 0:\n",
    "      model.add(Dense(n, activation = activations[i], input_dim = width))\n",
    "    else:\n",
    "      model.add(Dense(n, activation = activations[i]))\n",
    "\n",
    "  # output\n",
    "  model.add(Dense(outputs, activation = \"linear\"))\n",
    "  \n",
    "  # return the model\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f461a21",
   "metadata": {},
   "source": [
    "Set up the target names and create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34cd60cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\matsiuk\\AppData\\Local\\anaconda3\\envs\\gametrick\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "target_names = ['amplitude','X','Y']\n",
    "model = create_sequential_dnn(900, outputs = len(target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc436509",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "09e9b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer\n",
    "opt = Adam(learning_rate = 1e-3)\n",
    "model.compile(loss = \"mse\", optimizer = opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a5e98c",
   "metadata": {},
   "source": [
    "Fit the model with train dataset and validate it with validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8fecfef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 0s 25us/sample - loss: 107.9014 - val_loss: 252.1645\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 25us/sample - loss: 107.8687 - val_loss: 248.7223\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 25us/sample - loss: 105.7453 - val_loss: 251.6060\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 105.2805 - val_loss: 246.3599\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 26us/sample - loss: 103.8630 - val_loss: 248.4045\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 104.2526 - val_loss: 240.6402\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 26us/sample - loss: 105.0792 - val_loss: 250.5122\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 26us/sample - loss: 102.8278 - val_loss: 244.0753\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 103.5494 - val_loss: 254.5702\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 25us/sample - loss: 103.5108 - val_loss: 244.2423\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 100.1232 - val_loss: 245.9782\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 26us/sample - loss: 99.2242 - val_loss: 239.9934\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 25us/sample - loss: 100.9539 - val_loss: 244.4652\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 25us/sample - loss: 99.9907 - val_loss: 238.9145\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 26us/sample - loss: 98.0022 - val_loss: 240.2271\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 98.2345 - val_loss: 244.2324\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 26us/sample - loss: 98.5107 - val_loss: 239.9746\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 97.3881 - val_loss: 233.3851\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 26us/sample - loss: 97.0115 - val_loss: 234.6698\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 96.9398 - val_loss: 235.9326\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 26us/sample - loss: 96.2013 - val_loss: 236.1954\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 94.3417 - val_loss: 233.3891\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 26us/sample - loss: 94.8494 - val_loss: 231.8493\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 26us/sample - loss: 93.7401 - val_loss: 246.1389\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 96.0425 - val_loss: 229.3097\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 92.7750 - val_loss: 227.9859\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 26us/sample - loss: 91.9715 - val_loss: 227.1873\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 92.5434 - val_loss: 226.6866\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 26us/sample - loss: 92.4817 - val_loss: 224.4762\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 26us/sample - loss: 91.3328 - val_loss: 226.0354\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 25us/sample - loss: 90.4248 - val_loss: 236.9723\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 25us/sample - loss: 91.4360 - val_loss: 230.1882\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 90.2823 - val_loss: 230.9118\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 26us/sample - loss: 90.1828 - val_loss: 232.2723\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 91.7270 - val_loss: 225.8683\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 26us/sample - loss: 89.8355 - val_loss: 224.1752\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 90.3219 - val_loss: 219.2286\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 88.0613 - val_loss: 227.2879\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 26us/sample - loss: 89.8998 - val_loss: 220.3458\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 26us/sample - loss: 87.9628 - val_loss: 228.5925\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 88.3328 - val_loss: 222.8485\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 0s 27us/sample - loss: 86.1140 - val_loss: 220.7462\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 0s 25us/sample - loss: 85.2876 - val_loss: 220.2944\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 25us/sample - loss: 87.4304 - val_loss: 228.4178\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 87.3451 - val_loss: 217.9013\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 85.4527 - val_loss: 218.9709\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 0s 26us/sample - loss: 84.7158 - val_loss: 220.1444\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 0s 26us/sample - loss: 84.0469 - val_loss: 215.1287\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 85.5608 - val_loss: 219.5150\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 0s 27us/sample - loss: 83.8603 - val_loss: 220.2563\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = df_train_X, y = df_train_y[:], \n",
    "        validation_data = (df_test_X, df_test_y[:]),\n",
    "        epochs = 50, batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c850b01b",
   "metadata": {},
   "source": [
    "Predict the outputs for test dataset and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5410ceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(df_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "99f1f270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 12us/sample - loss: 220.2563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "220.25632720947266"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=df_test_X, y=df_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f797a14f",
   "metadata": {},
   "source": [
    "Predict the outputs for judge dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4043eec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape:  (2000, 900)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amplitude</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.020967</td>\n",
       "      <td>290.168945</td>\n",
       "      <td>-77.878807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.368213</td>\n",
       "      <td>172.946609</td>\n",
       "      <td>-844.473511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.151659</td>\n",
       "      <td>-24.089024</td>\n",
       "      <td>32.475533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.134604</td>\n",
       "      <td>550.524414</td>\n",
       "      <td>-175.967468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.053262</td>\n",
       "      <td>-281.069336</td>\n",
       "      <td>-353.006653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1.519884</td>\n",
       "      <td>-903.620300</td>\n",
       "      <td>368.979401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>3.874111</td>\n",
       "      <td>305.609619</td>\n",
       "      <td>-245.970673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2.829836</td>\n",
       "      <td>285.808899</td>\n",
       "      <td>-33.228050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>3.899166</td>\n",
       "      <td>-449.398224</td>\n",
       "      <td>147.527237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3.910190</td>\n",
       "      <td>618.196472</td>\n",
       "      <td>-113.265221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      amplitude           X           Y\n",
       "0      4.020967  290.168945  -77.878807\n",
       "1      3.368213  172.946609 -844.473511\n",
       "2      3.151659  -24.089024   32.475533\n",
       "3      3.134604  550.524414 -175.967468\n",
       "4      4.053262 -281.069336 -353.006653\n",
       "...         ...         ...         ...\n",
       "1995   1.519884 -903.620300  368.979401\n",
       "1996   3.874111  305.609619 -245.970673\n",
       "1997   2.829836  285.808899  -33.228050\n",
       "1998   3.899166 -449.398224  147.527237\n",
       "1999   3.910190  618.196472 -113.265221\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read judge csv \n",
    "df_judge = pd.read_csv(os.path.join(source,\"judge.csv\"), na_values=['NA', '?'], header=None)\n",
    "\n",
    "#Get inputs\n",
    "df_judge_X = retrieve_X_df(df_judge)\n",
    "\n",
    "#Predict the outputs \n",
    "preds_judge = model.predict(df_judge_X)\n",
    "\n",
    "#Put the predictions into the dataframe\n",
    "output_judge = pd.DataFrame({'amplitude':preds_judge[:,0].flatten(),\n",
    "                      'X':preds_judge[:,1].flatten(),'Y':preds_judge[:,2].flatten()})\n",
    "output_judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eba4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the csv-file with outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0bcec8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/matsiuk/Documents/Python Scripts/DATA/Problem1\"\n",
    "output_judge.to_csv(os.path.join(path,\"output_judge_Pr1_seq_model_with_3_outputs.csv\"),index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gametrick",
   "language": "python",
   "name": "gametrick"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
